<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta charset="utf-8">
<title>実践知能アプリケーション構築フレームワークPRINTEPSの開発と社会実践</title>
<meta name="description" content="">
<meta name="keywords" content="">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="format-detection" content="telephone=no">
<link rel="shortcut icon" href="images/favicon.ico">
<link rel="stylesheet" type="text/css" href="style.css" media="all">
<!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
<![endif]-->
</head>
<body>
<header class="globalHeader">
	<div class="wrap cf">
		<h1><strong><img src="images/logo.png" width="122" height="30" alt="プリンテップス" /></strong><span>JST/CREST「実践知能アプリケーション構築フレームワーク<br>PRINTEPSの開発と社会実践」(2014.10-2020.3)</span></h1>
		<nav>
			<ul>
				<li><a href="#work">研究内容</a></li>
				<li><a href="#member">研究メンバー</a></li>
				<li><a href="publications.html#result">研究業績</a></li>
				<li><a href="activities.html#history">活動履歴</a></li>
			</ul>
		</nav>
		<ul>
			<li style="float:left;padding:0 10px 0 30px;border-right:1px solid #aaa;"><a href="index.html">日本語</a></li>
			<li style="margin-left:10px;float:left;"><a href="index_en.html">English</a></li>
		</ul>
	</div>
</header>
<!-- /.globalHeader -->

<article role="main">
	<div class="splash">
		<div class="wrap">
			<h2><img src="images/splash_img.png" width="400" height="412" alt="プリンテップス［知識推論/音声対話/］" /></h2>
			<div>
				<p>本研究JST/CREST「実践知能アプリケーション構築フレームワーク PRINTEPS（読み方：プリンテプス、以降PRINTEPS）の開発と社会実践」(2014.10-2020.3)は、開発者向けではなく、ユーザ自身が、聞いて話して（音声対話）、考えて（知識推論）、見て動いて（画像センシング・動作）という一連の知的振舞いを実行する人工知能・知能ロボットアプリケーションを数時間から数日で開発でき、その知的振舞いを見て考察・再発見することで、知のPDCAサイクルがまわり、ユーザと人工知能・知能ロボット間の知能共進化（Co-evolution of Intelligence）が起こるプラットフォームの開発を目指しています。</p>
				<p>PRINTEPSは、ユーザにとって必要なAIアプリケーションをユーザ自身が開発できるプラットフォームであり、多様なAIアプリを社会に普及させるためのエンジンです。</p>
			</div>
		</div>
	</div>

	<section class="news-content">
		<h1>News</h1>
		<ul class="default">
			<li>2017年10月7日(土)-8日(日)： 慶應義塾大学理工学部の矢上祭で，ロボット喫茶店を出店します <a href="https://www.yagami-dr.com/"><em>オンライン予約受付中</em></a></li>
			<li>2017年11月18日(土）： 第１回クラスルームＡＩシンポジウム開催 <a href="./classroom_ai"><em>参加申込はこちら</em></a></li>
		</ul>
		<br/>
	</section>
	<!--
	<div class="news">		
			<dl class="news-texts">
				<dt title="file">NEWS</dt>
				<br/><br/>
				<dd>
					<ul>
						<li><em></em><a href="/"></a></li>					
					</ul>
				</dd>
			</dl>
			
			<div class="news-pager">
				<a class="news-pager-prev" href="#" title="left">&lt;</a>
				<span class="news-pager-number"></span>
				<a class="news-pager-next" href="#" title="right">&gt;</a>
			</div>
		</div>
	</div>
		-->
	
	<div class="leader">
		<div class="wrap cf">
			<div class="textArea">
				<h2>PRINTEPSとは</h2>
				<p>PRINTEPSは、知識推論、音声対話、人と物体の画像センシング、動作という4種類の要素知能（バックグラウンドで学習）を統合した総合知能アプリの開発を目標にするとともに、開発者向けではなく、ユーザが設計段階から参加し（ユーザ参加型デザイン)、ユーザがソフトウェア（SW）モジュール結合によりAIアプリケーションをアジャイルに（数時間から数日で）開発できることを目指しています。</p>
			</div>
			<div class="movieArea">
				<iframe width="416" height="234" src="https://www.youtube.com/embed/UoPjWpdEny8?rel=0" frameborder="0" allowfullscreen></iframe>
				<iframe width="416" height="234" src="https://www.youtube.com/embed/_zL_olQz6us?rel=0" frameborder="0" allowfullscreen></iframe>
			</div>
		</div>
	</div>
	
	
	<section id="work" class="content work">
		<h1>研究内容</h1>
		<div class="tabs">
			<ul class="cf">
				<li class="current"><a href="/">ワークフローエディター</a></li>
				<li><span>&emsp;</span></li>
				<li><span>&emsp;</span></li>
			</ul>
		</div>
		<div class="tabBlock">
			<div class="wrap">
				<div  class="columnSet cf">
					<div class="leftCol">
						<ul class="popupGallery cf">
							<li><a href="javascript:void(0);" title="（1）喫茶店サービスルート"><img src="images/workflow_process01.jpg" width="316" height="218" alt="（1）喫茶店サービスルート" /></a><p>（1）喫茶店サービスルート</p></li>
							<li><a href="javascript:void(0);" title="（2）入店時対応サービス"><img src="images/workflow_process02.jpg" width="316" height="218" alt="（2）入店時対応サービス" /></a><p>（2）入店時対応サービス</p></li>
							<li><a href="javascript:void(0);" title="（3）お客様に挨拶プロセス"><img src="images/workflow_process03.jpg" width="316" height="218" alt="（3）お客様に挨拶プロセス" /></a><p>（3）お客様に挨拶プロセス</p></li>
							<li><a href="javascript:void(0);" title="（4）来客検知プロセス"><img src="images/workflow_process04.jpg" width="316" height="218" alt="（4）来客検知プロセス" /></a><p>（4）来客検知プロセス</p></li>
						</ul>
					</div>
					<div class="rightCol">
						<p>PRINTEPSにおけるワークフローエディタは、サービス、プロセス、モジュールを組み合わせたワークフローを構築するだけで、知識推論・学習、音声対話、人と物体の画像センシング、マニュピュレーション・動作という4種類の要素知能を統合した総合知能アプリを、エンドユーザが容易に開発できることを目指したWebアプリケーションです。</p>
						<p>構築したワークフローは、代表的なロボット開発環境であるROS (Robot Operating System)上で実行可能なPythonのソースコードに自動変換することが可能です。</p>
						<p>知能ロボットのために、聞いて話して（音声対話）、考えて（知識推論、機械学習）、見て動いて（画像センシング、マニュピュレーション）という一連の知的振舞いを、エンドユーザが俊敏（アジャイル）に開発して外在化させることを支援します。</p>
					</div>
				</div>
				<ul class="imageList cf">
					<li><img src="images/workflow_pdca01.png" width="357" height="196" alt="" /></li>
					<li><img src="images/workflow_pdca02.png" width="357" height="196" alt="" /></li>
					<li><img src="images/workflow_pdca03.png" width="357" height="196" alt="" /></li>
				</ul>
				<p>ユーザが知能ロボットの知的振舞いを見て考察・再発見することにより、知能のPDCAサイクルがまわりはじめ、知能共進化(Co-evolution of Intelligence)（人の知能と機械知能が互いに進化し続けていくことで，所与の問題が解決される）を実現できると考えています。</p>
			</div>
			<div class="wrap">
				<div style="font-size:1.5rem;color:#4BBFE3">このプロジェクトで使用されているロボット</div>
				<br/>
				<table class="robot_table">
					<tr>
					<td><img src="images/robots/Pepper.png" width="auto" height="130" alt="" /></td>
					<td><img src="images/robots/Nao.png" width="auto" height="130" alt="" /></td>
					<td><img src="images/robots/Sota.png" width="auto" height="130" alt="" /> </td>
					<td><img src="images/robots/SociBot.png" width="auto" height="130" alt="" /></td>
					<td><img src="images/robots/Hironx.png" width="auto" height="130" alt="" /></td>
					<td> <img src="images/robots/Baxter.png" width="auto" height="130" alt="" /></td>
					<td> <img src="images/robots/HSR.png" width="auto" height="130" alt="" /> </td>
					<td><img src="images/robots/JACO2.png" width="auto" height="130" alt=""/></td>
					</tr>
					<tr valign="top" style="text-align: center">
						<td><a href="https://www.aldebaran.com/ja/peppertoha">Pepper<br>&copy;SoftBank</a></td>
						<td><a href="https://www.aldebaran.com/ja/xiao-xing-robotutonaotoha">NAO<br>&copy;SoftBank</a></td>
						<td><a href="https://www.vstone.co.jp/products/sota/">Sota<br>&copy;Vstone</a></td>
						<td><a href="https://www.engineeredarts.co.uk/socibot/">SociBot<br>&copy;Engineered Arts</p></a></td>
						<td><a href="http://nextage.kawada.jp/hiro/">Hironx<br>&copy;KAWADA</p></a></td>
						<td><a href="http://www.rethinkrobotics.com/baxter/">Baxter<br>&copy;rethink robotics</a></td>
						<td><a href="http://www.toyota.co.jp/jpn/tech/partner_robot/">HSR<br>&copy;TOYOTA</a></td>
						<td><a href="http://www.kinovarobotics.com/assistive-robotics/products/manipulation/">JACO2<br>&copy;Kiova</a></td>
					</tr>
				</table>
			</div>
			<div class="btnArea">
				<a class="btn" href="http://ja-demo.printeps.org/description" target="_blank">デモサイトに移動する</a>
			</div>
		</div>
		
	</section>

	<section id="member" class="content member">
		<h1>研究メンバー</h1>
		<div class="wrap cf">
			<div class="group">
				<div class="groupBox">
					<h2>知識グループ</h2>
					<ul>
						<li><img src="images/profile_gp01_01.jpg" width="97" height="110" alt="山口高平" /><strong><a href="http://www.yamaguti.comp.ae.keio.ac.jp/index.ja.html">山口 高平</a></strong>慶應義塾大学理工学部<span>(研究代表者)</span></li>
						<li><img src="images/profile_gp01_05.jpg" width="97" height="110" alt="森田武史" /><strong><a href="http://researchmap.jp/t_morita/">森田 武史</a></strong>慶應義塾大学理工学部</li>
						<li><img src="images/profile_dummy.jpg" width="97" height="110" alt="鈴木忠" /><strong><a href="http://www.shirayuri.ac.jp/course/teacher/suzuki_tadashi.html">鈴木 忠</a></strong>白百合女子大学文学部</li>
						<li><img src="images/profile_dummy.jpg" width="97" height="110" alt="山﨑準二" /><strong>山﨑 準二</strong>学習院大学文学部</li>
					</ul>
				</div>
				<div class="groupBox">
					<h2>対話グループ</h2>
					<ul>
						<li><img src="images/profile_gp02_01.jpg" width="97" height="110" alt="中野有紀子" /><strong><a href="http://iui.ci.seikei.ac.jp/">中野 有紀子</a></strong>成蹊大学理工学部<span>(主たる共同研究者)</span></li>
						<li><img src="images/profile_dummy.jpg" width="97" height="110" alt="小林一郎" /><strong><a href="http://www.koba.is.ocha.ac.jp/wordpress/?lang=ja">小林 一郎</a></strong>お茶の水女子大学理学部<span>(主たる共同研究者)</span></li>
						<li><img src="images/profile_gp02_02.jpg" width="97" height="110" alt="高瀬裕" /><strong><a href="http://iui.ci.seikei.ac.jp/~takase/">高瀬 裕</a></strong>成蹊大学理工学部</li>
					</ul>
				</div>
				<div class="groupBox">
					<h2>画像センシング・動作グループ</h2>
					<ul>
						<li><img src="images/profile_gp03_01.jpg" width="97" height="110" alt="斎藤英雄" /><strong><a href="http://www.hvrl.ics.keio.ac.jp/">斎藤 英雄</a></strong>慶應義塾大学理工学部<span>(主たる共同研究者)</span></li>
						<li><img src="images/profile_gp03_05.jpg" width="97" height="110" alt="高橋正樹" /><strong><a href="http://www.yt.sd.keio.ac.jp/">高橋 正樹</a></strong>慶應義塾大学理工学部<span>(主たる共同研究者)</span></li>
						<li><img src="images/profile_gp03_04.jpg" width="97" height="110" alt="杉本麻樹" /><strong><a href="http://im-lab.net/">杉本 麻樹</a></strong>慶應義塾大学理工学部</li>
						<li><img src="images/profile_dummy.jpg" width="97" height="110" alt="萬礼応"/><strong>萬 礼応</strong>慶應義塾大学大学院理工学研究科</li>
						<li><img src="images/profile_dummy.jpg" width="97" height="110" alt="小篠裕子"/><strong>小篠 裕子</strong>慶應義塾大学大学院理工学研究科</li>
					</ul>
				</div>
			</div>
		</div>
	</section>

	<!--<section id="result" class="content result">
		<h1>研究業績</h1>
		<div class="btnArea">
			<a class="btn" href="javascript:void(0);">2015年度</a>
		</div>
		<div class="wrap cf 2015">
			<table class="dataFmt">
				<tr>
					<th>原著論文</th>
					<td><ul>
							<li>1.&nbsp;多川 勇介，田中 改，森田 武史，南 裕也，並河 大地，下村 道夫，山口 高平，”Linked Data とルールベースの統合に基づく食事療法支援サービスの開発と評価”，人工知能学会論文誌，Vol.31, No1 pp.16-28, 2016 (DOI: <a href="http://dx.doi.org/10.1527/tjsai.31-1_LOD-B" target="_blank">10.1527/tjsai.31-1_LOD-B</a>)</li>
							<li>2.&nbsp;Masahiko Yamamoto, Masafumi Hagiwara: “Moral Judgement System Using Evaluation Expressions,” International Journal of Affective Engineering, Vol.15, No.1, pp.153-161, 2016.(DOI: <a href="http://dx.doi.org/10.5057/jjske.TJSKE-D-15-00026" target="_blank">10.5057/jjske.TJSKE-D-15-00026</a>)</li>
							<li>3.&nbsp;Yusuke Nakayama, Hideo Saito, Masayoshi Shimizu, and Nobuyasu Yamaguchi, Marker-Less Augmented Reality Framework Using On-Site 3D Line-Segment-basedModel Generation, Journal of Imaging Science and Technology, vol. 60, no.2, pp.020401-1~020401-24, 2016.(DOI: <a href="http://dx.doi.org/10.2352/J.ImagingSci.Technol.2016.60.2.020401" target="_blank">10.2352/J.ImagingSci.Technol.2016.60.2.020401</a>)</li>
							<li>4.&nbsp;Shunta Saito, Takayoshi Yamashita and Yoshimitsu Aoki, “Multiple Objects Extraction from Aerial Imagery with Convolutional Neural Networks,” Journal of Imaging Science and Technology, Vol.60, No.1, pp. 10402-1-10402-9(9)、2016.(DOI: <a href="http://dx.doi.org/10.2352/J.ImagingSci.Technol.2016.60.1.010402" target="_blank">10.2352/J.ImagingSci.Technol.2016.60.1.010402</a>)</li>
							<li>5.&nbsp;Toshiki Yamanaka，Yutaka Takase, and Yukiko I. Nakano. Assessing the Communication Attitude of the Elderly using Prosodic Information and Head Motions. In Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts (HRI'16 Extended Abstracts). ACM, New York, NY, USA.	</li>
							<li>6.&nbsp;Yuki Kadono, Yutaka Takase, and Yukiko I. Nakano. Generating Iconic Gestures based on Graphic Data Analysis and Clustering. In Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts (HRI'16 Extended Abstracts). ACM, New York, NY, USA.	</li>
							<li>7.&nbsp;Vrzakova, H., Bednarik, R., Nakano, Y., Nihei, F.: Speakers' head and gaze dynamics weakly correlate in group conversation Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research & Applications, pp. 77-84, ACM, 2016. (DOI: <a href="http://dx.doi.org/10.1145/2857491.2857522" target="_blank">10.1145/2857491.2857522</a>)</li>
							<li>8.&nbsp;森田 武史，洪 潤基，斎藤 忍，飯島 正，山口 高平，”SCOR オントロジーに基づく生産管理プロセスモデリング支援ツールの実装”，情報システム学会誌，Vol.11 No.1 pp.13-47, 2015	</li>
							<li>9.&nbsp;Ayanori Yorozu, Masaki Takahashi, "Improved Leg Tracking Considering Gait Phase and Spline-based Interpolation during Turning Motion in Walk Tests", Sensors, Vol. 15, No.9, pp. 22451-22472, 2015. (DOI: <a href="http://dx.doi.org/10.3390/s150922451" target="_blank">10.3390/s150922451</a>)</li>
							<li>10.&nbsp;Ayanori Yorozu, Shu Nishiguchi, Minoru Yamada, Tomoki Aoyama, Toshiki Moriguchi and Masaki Takahashi, "Gait Measurement System for the Multi-Target Stepping Task Using a Laser Range Sensor", Sensors, Vol.15, No.5, pp. 11151-11168, 2015. (DOI: <a href="http://dx.doi.org/10.3390/s150511151" target="_blank">10.3390/s150511151</a>)</li>
							<li>11.&nbsp;Shunta Saito, Ryota Arai and Yoshimitsu Aoki, “Seamline Determination Based on Semantic Segmentation for Aerial Image Mosaicking,” IEEE Access, Vol. 3, pp. 2847-2856, 2015.(DOI: <a href="http://dx.doi.org/10.1109/ACCESS.2015.2508921" target="_blank">10.1109/ACCESS.2015.2508921</a>)</li>
							<li>12.&nbsp;Yukiko I. Nakano, Takashi Yoshino, Misato Yatsushiro, and Yutaka Takase. Generating Robot Gaze on the Basis of Participation Roles and Dominance Estimation in Multiparty Interaction. ACM Transactions on Interactive Intelligent Systems. 5, 4, Article 22 (December 2015), 23 pages.(DOI: <a href="http://dx.doi.org/10.1145/2743028" target="_blank">10.1145/2743028</a>)</li>
							<li>13.&nbsp;高瀬裕，三武裕玄，長谷川晶一，中野有紀子：環境音の音場操作を用いた方向情報提示：感覚刺激の低減による聴覚ディスプレイ, ヒューマンインタフェース学会論文誌, Vol.17, No.2, pp. 179-190, 2015.		</li>
							<li>14.&nbsp;Yukiko I. Nakano, Sakiko Nihonyanagi, Yutaka Takase, Yuki Hayashi, and Shogo Okada. Predicting Participation Styles using Co-occurrence Patterns of Nonverbal Behaviors in Collaborative Learning, 17th ACM International Conference on Multimodal Interaction (ICMI2015), pp. 91-98, 2015.	</li>
							<li>15.&nbsp;Tatsuya Kimoto, Takeshi Morita, Takahito Ishii, Haryuya Suga, Yu Sugawara, Takashi Beppu and Takahira Yamaguchi，”Integrating Heterogeneous Data Sources for Planning Road Reconstruction”, Knowledge-Based and Intelligent Information & Engineering Systems 19th Annual Conference, KES-2015, Procedia Computer Science, Volume 60, pp.1720-1727, 2015 (DOI: <a href="http://dx.doi.org/10.1016/j.procs.2015.08.302" target="_blank">10.1016/j.procs.2015.08.302</a>)</li>
							<li>16.&nbsp;Ayanori Yorozu, Masaki Takahashi, Development of Gait Measurement Robot Using Laser Range Sensor for Evaluating Long-distance Walking Ability in the Elderly, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2015), pp.4888-4893, 2015(DOI: <a href="http://dx.doi.org/10.1109/IROS.2015.7354064" target="_blank">10.1109/IROS.2015.7354064</a>)</li>
						</ul></td>
				</tr>
				<tr>
					<th>招待講演</th>
					<td><ul>
							<li>1.&nbsp;山口高平	AI分野における技術動向と実践的な教育	情報処理学会第78回全国大会	慶應義塾大学矢上キャンパス	2016/3/11</li>
							<li>2.&nbsp;萩田紀博，山口高平，長井隆行，山田智広	『実用化に向けたクラウドネットワークロボット』～クラウドネットワークロボットがないとできない実用化とは？～，～本当にできるのか？シンボル・グラウンディング～	電子情報通信学会，クラウドネットワークロボット研究会	慶應義塾大学 日吉キャンパス 来往舎 大会議室 	2015/12/17</li>
							<li>3.&nbsp;萩原将文	Sympathetic Intelligence: Integration of Intelligence, Emotion and Will	International Symposium on Advanced Intelligent Systems (ISIS2015)	Mokpo, Korea	2015/11/5</li>
							<li>4.&nbsp;山口高平	知識型 AI の動向と社会への影響	電子情報通信学会，クラウドネットワークロボット研究会	筑波大学 東京キャンパス １階１１７室	2015/6/29</li>
							<li>5.&nbsp;青木義満	実環境下における頑健な人物画像センシング技術と産業応用	電子情報通信学会BioX研究会	金沢，日本	2015/6/29</li>
							<li>6.&nbsp;新井紀子，橋田浩一，武田 浩一，山口高平	ロボットは東大に入れるか，パネル討論	第29回人工知能学会全国大会	公立はこだて未来大学	2015/5/30</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>国際学会発表</th>
					<td>
						<ul>
							<li>1.&nbsp;Kunihiro Hasegawa, Hideo Saito	Diminished Reality for Hiding a Pedestrian using Hand-held Camera	International Workshop on Diminished Reality as Challenging Issue in Mixed and Augmented Reality (IWDR2015)	福岡国際会議場	2015/9/29</li>
							<li>2.&nbsp;Siim Meerits, Hideo Saito	Real-Time Diminished Reality for Dynamic Scenes	International Workshop on Diminished Reality as Challenging Issue in Mixed and Augmented Reality (IWDR2015)	福岡国際会議場	2015/9/29</li>
							<li>3.&nbsp;Y.Sugawara, T.Morita, S.Saito and T.Yamaguchi	An Intelligent Application Development Platform for Service Robots	Workshop on Multimodal Semantics for Robotic Systems (MuSRobS), IEEE/RSJ International Conference on Intelligent Robots and Systems 2015	Hamburg, Germany	2015/9/28</li>
							<li>4.&nbsp;H.Suga, T.Morita, and T.Yamaguchi	Primary School Teacher -Robot Collaboration with Multiple Information Sources	Workshop on Bridging user needs to deployed applications of service robots, IEEE/RSJ International Conference on Intelligent Robots and Systems 2015	Hamburg, Germany	2015/9/28</li>
							<li>5.&nbsp;T. Yamaguchi	A Platform PRINTEPS to Develop Practical Intelligent Applications	Workshop on Towards Wisdom Computing: Harmonious Collaboration Between People and Machines, 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing Adjunct Publication	Congre Convention Hall B04 B2th Floor, Grand Front Osaka Tower-C 3-1 Ofuka-cho, Kita-ku, Osaka	2015/9/7</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>国内学会発表</th>
					<td><ul>
							<li>1.&nbsp;工藤康統，齋藤俊太，青木義満	Convoluational Neural Networkを用いた人物周辺の環境を考慮した行動認識	電子情報通信学会PRMU研究会	台場　産業技術総合研究所	2016/3/25</li>
							<li>2.&nbsp;菅原 優，丸川 大輝，森田 武史，山口 高平	PRINTEPSにおけるイベントを通したルールと画像センシングの統合～喫茶店業務への適用1～	情報処理学会第78回全国大会	慶應義塾大学矢上キャンパス	2016/3/11</li>
							<li>3.&nbsp;石井 誉仁，中村 高大，八馬 遼，中山 祐介，森田 武史，山口 高平	PRINTEPSにおけるオントロジーとマニピュレーションの統合～喫茶店業務への適用２～	情報処理学会第78回全国大会	慶應義塾大学矢上キャンパス	2015/3/11</li>
							<li>4.&nbsp;菅　陽哉，西本智浩，赤柴駿介，柊原礼士，桑山美冴，山口高平	PRINTEPSにおけるマルチヒューマンロボット連携チャネルの設計～小学校授業実践への適用～	情報処理学会第78回全国大会	慶應義塾大学矢上キャンパス	2015/3/11</li>
							<li>5.&nbsp;番原常公，中山祐介，齋藤俊太，斎藤英雄	実践知能アプリケーション開発プラットフォームPRINTEPSのためのRGB-Dカメラによるテーブルトップ作業空間の状況認識	情報処理学会　第78回全国大会	横浜，慶應義塾大学矢上キャンパス	2016/3/11</li>
							<li>6.&nbsp;田中康浩，中山祐介，齋藤俊太，斎藤英雄	実践知能アプリケーション開発プラットフォームPRINTEPSのためのRGB-Dカメラによる来場者検出と属性判定	情報処理学会　第78回全国大会	横浜，慶應義塾大学矢上キャンパス	2016/3/11</li>
							<li>7.&nbsp;森田武史，西村良太，山口高平	ストリーム推論とROSに基づく総合知能アプリケーション開発ツールPRINTEPS	電子情報通信学会，クラウドネットワークロボット研究会	慶應義塾大学 日吉キャンパス 来往舎 大会議室 	2015/12/18</li>
							<li>8.&nbsp;八馬　遼・中山祐介・齋藤俊太・斎藤英雄	ロボットによる物体把持のための部分形状モデルを用いた物体認識	電子情報通信学会 クラウドネットワークロボット研究会（CNR）	横浜，慶應義塾大学日吉キャンパス	2015/12/18</li>
							<li>9.&nbsp;萬　礼応・高橋正樹	長距離歩行能力評価のための歩行計測ロボット	電子情報通信学会 クラウドネットワークロボット研究会（CNR）	横浜，慶應義塾大学日吉キャンパス	2015/12/18</li>
							<li>10.&nbsp;山中俊貴	発話の韻律情報と頭部移動情報に基づく高齢者の会話活動評価値の予測，	HCGシンポジウム2015	富山国際会議場	2015/12/16</li>
							<li>11.&nbsp;筒井瑳斗志，森田武史，山口高平	Extending DBpedia with List Structures in Wikipedia Articles	第36回セマンティックウェブとオントロジー研究会-DBpediaシンポジウム	国立情報学研究所　12F会議室（1208/1210室）	2015/7/9</li>
							<li>12.&nbsp;萬礼応，森口智規, 高橋正樹	旋回運動時の歩行位相を考慮した両脚トラッキング	第 14 回「運動と振動の制御」シンポジウム(MOVIC2015)	宇都宮, 日本	2015/6/22</li>
							<li>13.&nbsp;齋藤俊太，山下隆義，青木義満	Convolutional Neural Networkを用いた航空画像からの道路・建物抽出	第21回画像センシングシンポジウム	横浜，パシフィコ横浜	2015/6/12</li>
							<li>14.&nbsp;門野　友城	隠喩的ジェスチャの分析とジェスチャ自動付与に向けた検討，第29回人工知能学会全国大会，3D4-4 (2015年6月1日)，函館未来大学．	第29回人工知能学会全国大会	函館未来大学	2015/6/1</li>
							<li>15.&nbsp;森田武史，山口高平	PRINTEPSアーキテクチャの構成と実践	第29回人工知能学会全国大会	公立はこだて未来大学	2015/5/30</li>
							<li>16.&nbsp;山口高平，中野有紀子，斎藤英雄，森田武史，青木義満，萩原将文，斎藤俊太	知能共進化のための実践知能アプリケーションプラットフォームPRINTEPS	第29回人工知能学会全国大会	公立はこだて未来大学	2015/5/30</li>
							<li>17.&nbsp;菅陽哉，森雄一郎，森田武史，山口高平	PRINTEPS を利用した小学校社会科教育実践	第29回人工知能学会全国大会	公立はこだて未来大学	2015/5/30</li>
							<li>18.&nbsp;高瀬 裕	砂遊びを通したインタラクティブな地図記号学習支援システムの提案，第29回人工知能学会全国大会，1N3-3 (2015年5月)	第29回人工知能学会全国大会	函館未来大学	2015/5/30</li>
							<li>19.&nbsp;吉野 尭	会話エージェントによる優位性推定に基づくグループ会話への介入，第29回人工知能学会全国大会，1I4-4 (2015年5月30日)，函館未来大学．	第29回人工知能学会全国大会	函館未来大学	2015/5/30</li>
							<li>20.&nbsp;田村 吉宏	Wikipediaを用いた質問応答と多肢選択問題による歴史学習，第29回人工知能学会全国大会，1N2-2 (2015年5月30日)， 函館未来大学	第29回人工知能学会全国大会	函館未来大学	2015/5/30</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>ポスター発表</th>
					<td><ul>
							<li>1.&nbsp;Rintaro Manabe	User Modeling and Reception Interaction by Service Robots. HRI2016 workshop on the challenge (not) to go wild! Challenges and best practices to study HRI in natural interaction settings.	HRI2016	New Zealand	2016/3/7</li>
							<li>2.&nbsp;Kimimasa Tamura	Model Based 3D Gaze Estimation from a Monocular Camera	FCV2016	Takayama, Japan	2016/2/18</li>
							<li>3.&nbsp;Masayuki Sano, Kazuki Matsumoto, Bruce Thomas, Hideo Saito	Rubix: Dynamic Spatial Augmented Reality by Extraction of Plane Regions with a RGB-D Camera	2015 IEEE International Symposium on Mixed and Augmented Reality (ISMAR2015)	福岡国際会議場	2015/9/30</li>
							<li>4.&nbsp;Naoto Ienaga, Hideo Saito, Kouichi Tezuka, Yasumasa Iwamura and Masayoshi Shimizu	Combination Photometric Stereo Using Compactness of Albedo and Surface Normal in the Presence of Shadows and Specular Reflection	CAIP2015	Malta	2015/9/1</li>
							<li>5.&nbsp;佐野 真之, Bruce Thomas, 斎藤 英雄	RGB-Dカメラを用いた平面領域抽出による動的な空間型ARの実現	第18回画像の認識・理解シンポジウム(MIRU2015)	大阪　ホテル阪急エキスポパーク	2015/7/30</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>その他著作物（総説、書籍）など</th>
					<td>
						<ul>
							<li>1.&nbsp;川村 隆浩, 森田 武史, 福田 直樹，”Linked Dataとセマンティック技術の海外動向”，人工知能学会誌 Vol.30 No.5 pp.580-589, 2015</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>受賞</th>
					<td>
						<ul>
							<li>1.&nbsp;田中康浩	情報処理学会全国大会学生奨励賞	情報処理学会	横浜	2016/3/11</li>
							<li>2.&nbsp;Yusuke Nakayama, Hideo Saito, Masayoshi Shimizu, and Nobuyasu Yamaguchi Best Paper Award Electronic Imaging 2016, Image Processing: Machine Vision Applications IX, 2016 サンフランシスコ 2016/2/17</li>
							<li>3.&nbsp;山口高平	情報システム学会第11回全国大会・研究発表大会ベストペーパー賞	情報システム学会	神奈川	2015/11/21</li>
							<li>4.&nbsp;山口高平	情報システム学会功績賞	情報システム学会	神奈川	2015/11/21</li>
							<li>5.&nbsp;山口高平	平成26年度人工知能学会 功績賞	人工知能学会	神奈川	2015/6/12</li>
							<li>6.&nbsp;家永直人	研究奨励賞	精密工学会		</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>報道</th>
					<td><ul>
							<li>1.&nbsp;読売新聞	人工知能ロボ　小学校教壇に	2016/1/26</li>
							<li>2.&nbsp;TBSラジオ	荻上チキ　Session-22【Main Session】 ダボス会議での報告書で明らかに。人工知能の台頭は、失業をもたらすのか	2016/1/25</li>
							<li>3.&nbsp;私立中高進学通信	特集「未来に備える教育　変化の激しい時代を生きるために」	2016/1/12</li>
							<li>4.&nbsp;CNET Japan （Web）	情報システム学会第11回全国大会・研究発表大会における「ベストペーパー賞」は山口 高平氏（慶應義塾大学）に授与	2015/11/26</li>
							<li>5.&nbsp;日本経済新聞	［真相深層］人工知能研究の世界競争激化　中国も「東大合格ロボ」開発　米先行、日本は官民連携を	2015/9/18</li>
							<li>6.&nbsp;読売新聞	人工知能開発 政府が強化 避難行動予測システムなど 実証実験や人材育成	2015/9/7</li>
							<li>7.&nbsp;日刊工業新聞	［CORE］人を超えるAI　深層学習技術で進化　「言語の理解」に課題残る	2015/8/3</li>
							<li>8.&nbsp;慶応塾生新聞	理工学部市民講座 行政 生活 医療 ビッグデータで切り開く未来	2015/8/3</li>
							<li>9.&nbsp;日刊工業新聞	［ロボット革命］人工知能センター設立　ビッグデータなど　慶大、要素技術統合	2015/7/31</li>
							<li>10.&nbsp;三田評論　2015年6月号	特集　人工知能と人間の未来　＜座談会＞人工知能は社会を変えるか	2015/6/1</li>
							<li>11.&nbsp;日刊工業新聞	ビッグデータ講座（理工学部市民講座）	2015/5/19</li>
							<li>12.&nbsp;日刊工業新聞	［レーザー］楽観的過ぎる	2015/4/27</li>
						</ul>
					</td>
				</tr>
			</table>
			<!-- <div class="btnArea">
				<a class="btn" href="javascript:void(0);" target="_blank">すべて見る</a>
			</div>
		</div>
		<div class="btnArea">
			<a class="btn" href="javascript:void(0);">2014年度</a>
		</div>
		<div class="wrap cf 2014">
			<table class="dataFmt">
				<tr>
					<th>原著論文</th>
					<td><ul>
							<li>1.&nbsp;中山祐介, 斎藤英雄, 清水雅芳, 山口伸康，“カメラ位置姿勢推定のためのRGB-Dカメラによる3次元線分モデル生成法”, 映像情報メディア学会誌, vol. 69, No. 4, pp. J148-J159, 2015 (DOI: <a href="http://dx.doi.org/10.3169/itej.69.J148" target="_blank">10.3169/itej.69.J148</a>)</li>
							<li>2.&nbsp;Shunta Saito and Yoshimitsu Aoki, “Building and road detection from large aerial imagery”, Proc. SPIE 9405, Image Processing: Machine Vision Applications VIII, 94050K ,February 27, 2015, (DOI:<a href="http://dx.doi.org/10.1117/12.2083273" target="_blank" >10.1117/12.2083273</a>)</li>
							<li>3.&nbsp;Yusuke Nakayama, Hideo Saito, Masayoshi Shimizu, and Nobuyasu Yamaguchi, “Marker-less AR system based on line segment feature”, Proc. SPIE 9392, The Engineering Reality of Virtual Reality 2015, 93920I, March 17, 2015, (DOI:<a href="http://dx.doi.org/10.1117/12.2083673" target="_blank">10.1117/12.2083673</a>)</li>
							<li>4.&nbsp;Yohei Ogura, Takuya Ikeda, Francois de Sorbier, and Hideo Saito, “Illumination Estimation and Relighting using an RGB-D Camera”, Proc. The International Conference on Computer Vision Theory and Applications (VISAPP2015), pp.305-312, March, 2015, (DOI:<a href="http://dx.doi.org/10.5220/0005295403050312" target="_blank">10.5220/0005295403050312</a>)</li>
							<li>5.&nbsp;N.Marumo, T.Beppu and T.Yamaguchi, “A Knowledge Transfer System Integrating Workflow, a Rule Base and a Goal Tree Based On Domain Ontologies”, International Conference on Knowledge Science, Engineering and Management (KSEM2014), Springer LNAI 8793 pp. 357-367, October, 2014, (DOI: <a href="http://dx.doi.org/10.1007/978-3-319-12096-6_32" target="_blank">10.1007/978-3-319-12096-6_32</a>)</li>
							<li>6.&nbsp;Y.Ogawa, Y.Mori adn T.Yamaguchi, “Applying Semantic Web Services to Multi-Robot Coordination”, WS on Real-World HRI, 16th ACM International Conference on Multimodal Interaction (ICMI2014) pp. 29-30, November, 2014, (DOI: <a href="http://dx.doi.org/10.1145/2666499.2669640" target="_blank">10.1145/2666499.2669640</a>)</li>
							<li>7.&nbsp;Y.Mori, Y.Ogawa, A.Hikawa and T.Yamaguchi, “Multi-Robot Coordination Based on Ontologies and Semantic Web Service”, The 2014 Pacific Rim Knowledge Acquisition Workshop (PKAW2014), Springer LNAI 8863 pp. 150-164, December, 2014 (DOI: <a href="http://dx.doi.org/10.1007/978-3-319-13332-4_13" target="_blank">10.1007/978-3-319-13332-4_13</a>)</li>
							<li>8.&nbsp;Takashi Yoshino, Yutaka Takase, and Yukiko I. Nakano, ” Controlling Robot’s Gaze according to Participation Roles and Dominance in Multiparty Conversations”, In Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts (HRI’15 Extended Abstracts). ACM, New York, NY, USA, pp. 127-128, 2015, (DOI: <a href="http://dx.doi.org/10.1145/2701973.2702012" target="_blank">10.1145/2701973.2702012</a>)</li>
							<li>9.&nbsp;Takashi Yoshino, Yuki Hayashi, and Yukiko I. Nakano, “Determining robot gaze according to participation roles in multiparty conversations”, In Proceedings of the second international conference on Human-agent interaction (HAI ’14). ACM, New York, NY, USA, 277-280, 2014, (DOI:<a href="http://dx.doi.org/10.1145/2658861.2658941" target="_blank">10.1145/2658861.2658941</a>)</li>
						</ul></td>
				</tr>
				<tr>
					<th>招待講演</th>
					<td><ul>
							<li>1.&nbsp;山口高平，マルチモーダルインタラクションに基づく知能共進化アーキテクチャ，リコンフィギャラブルシステム研究会，電子情報通信学会，慶應義塾大学，2015年1月29日</li>
							<li>2.&nbsp;山口高平，実践知能アプリケーション構築フレームワーク PRINTEPS の開発と社会実践，知のコンピューティング序章，情報処理学会第77回全国大会, 京都大学，2015年3月19日</li>
							<li>3.&nbsp;山口高平，パネル討論 知のコンピューティング，次の一歩，知のコンピューティング序章，情報処理学会第77回全国大会，京都大学，2015年3月19日</li>
							<li>4.&nbsp;T.Yamaguchi, A Knowledge Transfer System Based on the Integration of Workflow and Rule Base and Ontologies, the University of Vienna, October 14, 2014.</li>
							<li>5.&nbsp;T.Yamaguchi, Interdisciplinarity vs. Specialization in Robot Technology in Japan, KSEM2014, Sibiu, Romania, October 18, 2014.</li>
							<li>6.&nbsp;T.Yamaguchi, Wikipedia Ontology Engineering and Applications to Human Robot Interaction, PKAW2014, Gold Coast, Australia, December 2, 2014.<a href="http://www.pkaw.org/pkaw2014/" target="_blank">http://www.pkaw.org/pkaw2014/</a></li>
							<li>7.&nbsp;Yukiko Nakano, Understanding and modeling multiparty, multimodal interactions, In Proceedings of the workshop on From Modeling Multimodal and Multiparty Interactions to Designing Conversational Agents in ICMI2014, Istanbul, Turkey, November 16, 2014.<a href="http://ummmi.ilsp.gr/?page_id=18" target="_blank">http://ummmi.ilsp.gr/?page_id=18</a></li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>国際学会および国内学会発表</th>
					<td><ul>
							<li>1.&nbsp;稲田周平，渕澤雅志，石井誉仁，山口高平：産業用ロボットの活用に向けた作業改善の自動化 －サーブリッグを利用した基礎研究－，2014年秋季大会，日本経営工学会, 広島大学 東広島キャンパス, 2014年11月9日.</li>
							<li>2.&nbsp;山口高平，中野有紀子，森田武史，オントロジーに基づくヒューマンフレンドリーロボット，電子情報通信学会クラウドネットワークロボット研究会，東京大学，2014年12月4日.</li>
							<li>3.&nbsp;大野祐,牧山宅矢,荒川拓樹,森田武史,杉山岳弘,小薬洋昭,手嶋秀之,山口高平,浜松地域における高速道路からの立ち寄り観光推薦アプリの社会実験,第1回とうかい観光情報学研究会予稿集,pp.17-20, 静岡県立大学 ，2015年2月18日.</li>
							<li>4.&nbsp;森雄一郎，菅陽哉，菅原優，山口高平，知能共進化アーキテクチャに基づく小学生教育支援ロボット，情報処理学会第77回全国大会 1P-09，京都大学，2015年3月17日.</li>
							<li>5.&nbsp;牧山宅矢，大野祐，森田武史，杉山岳弘，小薬洋昭，手嶋秀之，山口高平，Linked Dataを利用した立ち寄り観光支援システムの社会実験，人工知能学会 第35回セマンティックウェブとオントロジー研究会，SIG-SWO-035-02，北九州国際会議場 22会議室，2015年3月23日.</li>
							<li>6.&nbsp;吉野　尭・高瀬　裕・中野有紀子 優位性と参与役割に応じたコミュニケーションロボットの視線制御, 電子情報通信学会ヒューマンコミュニケーション基礎研究会　信学技報, vol. 114, no. 440, HCS2014-77, pp. 25-30, ベイリゾート小豆島, 2015年1月30日.</li>
							<li>7.&nbsp;吉野　尭，高瀬　裕，中野有紀子優位性と参与役割に基づく視線制御モデルのコミュニケーションロボットへの応用 情報処理学会 第76回全国大会，2N-02. 京都大学, 2015年3月17日.</li>
							<li>8.&nbsp;田村吉宏，高瀬　裕，中野有紀子Wikipediaを用いた選択肢付き問題の生成手法 情報処理学会 第76回全国大会，2N-07. 京都大学, 2015年3月17日.</li>
							<li>9.&nbsp;斎藤英雄・萩原将文・青木義満・杉本麻樹，人間と機械の協調実現に向けた画像センシングと認識，電子情報通信学会クラウドネットワークロボット研究会，東京大学，2014年12月4日<a href="https://sites.google.com/site/cloudnetworkrobots/old/no15conf" target="_blank">https://sites.google.com/site/cloudnetworkrobots/old/no15conf</a></li>
							<li>10.&nbsp;篠塚祐紀子・斎藤英雄、視点生成型学習を用いたモデルベースカメラ位置姿勢推定、電子情報通信学会クラウドネットワークロボット研究会，東北大学，2015年2月20日</li>
							<li>11.&nbsp;大澤正彦，萩原将文、RBMにおける未学習データ検出法の提案と追加学習への応用、電子情報通信学会ニューロコンピューティング研究会，玉川大学, 2015年3月16日</li>
							<li></li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>ポスター発表</th>
					<td><ul>
							<li>1.&nbsp;佐野 真之, 松本 一紀, 斎藤 英雄, RGB-Dカメラ映像からのリアルタイム平面領域抽出による空間型ARの実現,情報処理学会コンピュータビジョンとイメージメディア2015年1月研究会，奈良先端科学技術大学院大学，2015年1月23日</li>
							<li>2.&nbsp;T.Morita, S.Tamagawa and T.Yamaguchi: Constructing a Class Hierarchy with Properties by Refining and Aligning Japanese Wikipedia Ontology and Japanese WordNet, 13th International Semantic Web Conference (ISWC2014), 9th International Workshop on Ontology Matching, Riva del Garda, Italy, October 20, 2014.</li>
							<li>3.&nbsp;T.Makiyama, Y.Ono, T.Morita, T.Yamaguchi, H.Kogusuri, T.Hideyuki and T.Sugiyama: Implementing Tourism Service Based on Linked Data with Social Experiments, Poster and Demonstartion, The Joint International Semantic Technology Conference (JIST) 2014, Chiang Mai, Thailand, November 10, 2014.</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>受賞・報道等</th>
					<td><ul>
							<li>1.&nbsp;二瓶 芙巳雄、林 佑樹、中野 有紀子：グループディスカッションにおける議論状態の変化の検出，第28回人工知能学会全国大会，4B1-2 (2014年5月)【全国大会優秀賞】</li>
							<li>2.&nbsp;毎日新聞　東京朝刊24面、［サイエンスカフェ］人工知能とのつきあい方、2014年10月23日</li>
							<li>3.&nbsp;J-WAVE、 JAM THE WORLD、人工知能について、2014年12月24日</li>
							<li>4.&nbsp;日刊工業新聞　朝刊24面、ロボットは先生より教え上手！？－慶大、小学生向けに環境問題の授業を開催、2015年3月30日</li>
						</ul>
					</td>
				</tr>
			</table>
			<!--<div class="btnArea">
				<a class="btn" href="javascript:void(0);" target="_blank">すべて見る</a>
			</div>
		</div>
	</section>-->

<!--
	<section id="history" class="content history">
		<h1>活動履歴</h1>
		<div class="btnArea">
			<a class="btn" href="javascript:void(0);">2015年度</a>
		</div>
		<div class="wrap cf 2015">
			<table class="dataFmt">
				<tr>
					<th>2015年4月17日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学矢上キャンパス 25棟 601</li>
							<li>人数：9人</li>
							<li>内容：研究進捗報告のためのミーティング</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年4月30日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学矢上キャンパス 26棟 2階</li>
							<li>人数：9人</li>
							<li>内容：研究進捗報告のためのミーティング</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年5月22日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学矢上キャンパス 07棟 205</li>
							<li>人数：16人</li>
							<li>内容：研究進捗報告のためのミーティング</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年6月26日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学矢上キャンパス 07棟 205</li>
							<li>人数：16人</li>
							<li>内容：研究進捗報告のためのミーティング</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年7月24日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学矢上キャンパス 26棟 207</li>
							<li>人数：15人</li>
							<li>内容：研究進捗報告のためのミーティング</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年8月31日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学矢上キャンパス 07棟 205</li>
							<li>人数：15人</li>
							<li>内容：研究進捗報告のためのミーティング</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年9月5日</th>
					<td><ul>
							<li>名称：第一回領域会議</li>
							<li>場所：ホテルコスモスクエア国際交流センター</li>
							<li>人数：46人</li>
							<li>内容：成果報告・学術交流</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年10月15日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学矢上キャンパス 07棟 205</li>
							<li>人数：13人</li>
							<li>内容：研究進捗報告のためのミーティング</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年11月6日</th>
					<td><ul>
							<li>名称：第二回領域会議</li>
							<li>場所：クロスウェーブ府中</li>
							<li>人数：90人</li>
							<li>内容：成果報告・学術交流</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年11月20日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学矢上キャンパス 07棟 205</li>
							<li>人数：10人</li>
							<li>内容：研究進捗報告のためのミーティング</li>
						</ul>
					</td>
				</tr>
			</table>
			<!-- <div class="btnArea">
				<a class="btn" href="javascript:void(0);" target="_blank">すべて見る</a>
			</div> 
		</div>
		<div class="btnArea">
			<a class="btn" href="javascript:void(0);">2014年度</a>
		</div>
		<div class="wrap cf 2014">
			<table class="dataFmt">
				<tr>
					<th>2014年10月21日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学矢上キャンパス 14棟 506</li>
							<li>人数：4人</li>
							<li>内容：平成26年度　第一回 領域会議に向けた打合せ</li>
							<li>総括：不参加</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2014年11月16日</th>
					<td><ul>
							<li>名称：7th Workshop on Eye Gaze in Intelligent Human Machine Interaction, 15h ACM International Conference on Multimodal Interaction (ICMI2014). (Co-Organizer)</li>
							<li>場所：Istanbul, Turkey</li>
							<li>人数：20人</li>
							<li>内容：視線を用いたHCIに関する国際ワークショップ</li>
							<li>総括：不参加</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年1月15日</th>
					<td><ul>
							<li>名称：サイトビジット</li>
							<li>場所：慶應義塾大学 矢上キャンパス 25棟 601</li>
							<li>人数：10人</li>
							<li>内容：プロジェクト進捗報告</li>
							<li>総括：参加</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年2月26日</th>
					<td><ul>
							<li>名称：DNPとの情報交換会（非公開）</li>
							<li>場所：慶應義塾大学 矢上キャンパス 26棟 207</li>
							<li>人数：10人</li>
							<li>内容：情報交換</li>
							<li>総括：不参加</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年3月6日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学 矢上キャンパス 14棟 506</li>
							<li>人数：3人</li>
							<li>内容：平成26年度第二回領域会議に向けた打合せ</li>
							<li>総括：不参加</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年3月7日，8日</th>
					<td><ul>
							<li>名称：平成26年度 第二回領域会議</li>
							<li>場所：クロス・ウェーブ府中 3階 304(大研修室B)</li>
							<li>人数：39人</li>
							<li>内容：学術交流</li>
							<li>総括：不参加</li>
						</ul>
					</td>
				</tr>
				<tr>
					<th>2015年3月7日，8日</th>
					<td><ul>
							<li>名称：チーム内ミーティング（非公開）</li>
							<li>場所：慶應義塾大学 矢上キャンパス 24棟 207</li>
							<li>人数：9人</li>
							<li>内容：グループ間の情報交換</li>
							<li>総括：不参加</li>
						</ul>
					</td>
				</tr>
			</table>
			<!--<div class="btnArea">
				<a class="btn" href="javascript:void(0);" target="_blank">すべて見る</a>
			</div>
		</div>
	</section>
	-->
	
	<div class="jst_logo">
		<a href="http://www.jst.go.jp/"><img src="images/jstlogo2015_rgb_ja.svg" height="80px" /></a>
	</div>
</article>

<footer class="globalFooter">
	<small>Copyright (C) 2014 - YAMAGUCHI CREST project All Rights Reserved.</small>
</footer>
<!-- /.footerGroup --> 


<!-- Loading JavaScript --> 
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<script type="text/javascript" src="js/jquery.easing.1.3.js"></script>
<script type="text/javascript" src="js/jquery.transit.min.js"></script>
<script type="text/javascript" src="js/jQueryAutoHeight.js"></script>
<script type="text/javascript" src="js/common.js"></script>


</body>
</html>
