<!DOCTYPE html>
<html lang="ja">

<head>
	<meta http-equiv="X-UA-Compatible" content="IE=edge" />
	<meta charset="utf-8" />
	<title>実践知能アプリケーション構築フレームワークPRINTEPSの開発と社会実践</title>
	<meta name="description" content="" />
	<meta name="keywords" content="" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<meta name="format-detection" content="telephone=no" />
	<link rel="icon" href="/images/favicon.ico" />
	<link rel="stylesheet" type="text/css" href="style.css" media="all" />
	<!--[if lt IE 9]>>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
<![endif]-->
</head>

<body>
	<header class="globalHeader">
		<div class="wrap cf">
			<h1>
				<strong>
					<img src="images/logo.png" width="122" height="30" alt="プリンテップス" />
				</strong>
				<span>JST/CREST「実践知能アプリケーション構築フレームワーク<br>PRINTEPSの開発と社会実践」(2014.10-2020.3)</span>
			</h1>
			<nav>
				<ul>
					<li>
						<a href="#news">ニュース</a>
					</li>
					<li>
						<a href="#work">研究内容</a>
					</li>
					<li>
						<a href="#member">研究メンバー</a>
					</li>
					<li>
						<a href="publications.html#result">研究業績</a>
					</li>
					<li>
						<a href="activities.html#history">活動履歴</a>
					</li>
				</ul>
			</nav>
			<ul>
				<li style="float:left;padding:0 10px 0 30px;border-right:1px solid #aaa;">
					<a href="index.html">日本語</a>
				</li>
				<li style="margin-left:10px;float:left;">
					<a href="index_en.html">English</a>
				</li>
			</ul>
		</div>
	</header>
	<!-- /.globalHeader -->

	<article role="main">
		<div class="splash">
			<div class="wrap">
				<h2>
					<img src="images/splash_img.png" width="400" height="412" alt="プリンテップス［知識推論/音声対話/］" />
				</h2>
				<div>
					<p>本研究JST/CREST「実践知能アプリケーション構築フレームワーク
						PRINTEPS（読み方：プリンテプス、以降PRINTEPS）の開発と社会実践」(2014.10-2020.3)は、開発者向けではなく、ユーザ自身が、聞いて話して（音声対話）、考えて（知識推論）、見て動いて（画像センシング・動作）という一連の知的振舞いを実行する人工知能・知能ロボットアプリケーションを数時間から数日で開発でき、その知的振舞いを見て考察・再発見することで、知のPDCAサイクルがまわり、ユーザと人工知能・知能ロボット間の知能共進化（Co-evolution
						of Intelligence）が起こるプラットフォームの開発を目指しています。</p>
					<p>PRINTEPSは、ユーザにとって必要なAIアプリケーションをユーザ自身が開発できるプラットフォームであり、多様なAIアプリを社会に普及させるためのエンジンです。</p>
				</div>
			</div>
		</div>

		<section id="news" class="news-content">
			<h1>ニュース</h1>
			<ul class="default">
				<li>2019年10月 3日(木)：PRINTEPSに関する記事が <a href="https://www.openaccessgovernment.org/">Open Access
						Government</a> に掲載されました ( <a
						href="http://edition.pagesuite-professional.co.uk/html5/reader/production/default.aspx?pubname=&edid=0d5ad7a6-fb33-40ea-b275-9a1234b94ddb&pnum=232">URL</a>)
				</li>
				<li>2019年 8月 3日(土)：「AIロボットを使った授業作りを学ぼう」第1回セミナーを開催しました</li>
				<li>2019年 2月 8日(金)：読売教育ネットワーク会報49号2019年1月号に議論支援ロボットの取り組みが掲載されました(<a
						href="https://kyoiku.yomiuri.co.jp/kaihou49a.pdf">URL</a>)
				</li>
				<li>2018年12月 1日(土)：PRINTEPSに関する記事が<a href="https://impact.pub/">Science Impact</a>に掲載されました ( <a
						href="https://doi.org/10.21820/23987073.2018.11.19">URL</a>)
				</li>
				<li> 2018年 2月28日(水)：読売教育ネットワーク会報38号2018年2月号に教師ロボット連携授業の取り組みが掲載されました(<a
						href="https://kyoiku.yomiuri.co.jp/kaihou38a.pdf">URL</a>)
				</li>
				<li> 2018年10月 6日(土)-7日(日)：慶應義塾大学理工学部の第19回矢上祭で，ロボット喫茶店を出店しました</li>
				<li> 2017年11月18日(土)： 第１回クラスルームＡＩシンポジウムを開催しました </li>
				<li> 2017年10月 7日(土)-8日(日)： 慶應義塾大学理工学部の第18回矢上祭で，ロボット喫茶店を出店しました </li>
				<li> 2016年12月28日(水)：読売教育ネットワーク会報24号2016年12月号に教師ロボット連携授業の取り組みが掲載されました(<a
						href="http://kyoiku.yomiuri.co.jp/kaihou24.pdf">URL</a>)
				</li>
			</ul>
			<br />
		</section>

		<!--
	<div class="news">		
			<dl class="news-texts">
				<dt title="file">NEWS</dt>
				<br/><br/>
				<dd>
					<ul>
						<li><em></em><a href="/"></a></li>					
					</ul>
				</dd>
			</dl>
			
			<div class="news-pager">
				<a class="news-pager-prev" href="#" title="left">&lt;</a>
				<span class="news-pager-number"></span>
				<a class="news-pager-next" href="#" title="right">&gt;</a>
			</div>
		</div>
	</div>
		-->

		<div class="leader">
			<div class="wrap cf">
				<div class="textArea">
					<h2>PRINTEPSとは</h2>
					<p>PRINTEPSは、知識推論、音声対話、人と物体の画像センシング、動作という4種類の要素知能（バックグラウンドで学習）を統合した総合知能アプリの開発を目標にするとともに、開発者向けではなく、ユーザが設計段階から参加し（ユーザ参加型デザイン)、ユーザがソフトウェア（SW）モジュール結合によりAIアプリケーションをアジャイルに（数時間から数日で）開発できることを目指しています。
					</p>
				</div>
				<div class="movieArea">
					<iframe width="416" height="234" src="https://www.youtube.com/embed/UoPjWpdEny8?rel=0"
						frameborder="0" allowfullscreen>
					</iframe>
					<iframe width="416" height="234" src="https://www.youtube.com/embed/_zL_olQz6us?rel=0"
						frameborder="0" allowfullscreen>
					</iframe>
				</div>
			</div>
		</div>


		<section id="work" class="content work">
			<h1>研究内容</h1>
			<div class="tabs">
				<ul class="cf">
					<li class="tab is-active">
						<span>PRINTEPS</span>
					</li>
					<li class="tab">
						<span>ロボット喫茶店</span>
					</li>
					<li class="tab">
						<span>教諭ロボット連携授業</span>
					</li>
				</ul>
			</div>
			<div class="tab-panel-group">
				<div class="tab-panel is-show">
					<div class="tabBlock">
						<div class="wrap">
							<div class="columnSet cf">
								<div class="leftCol">
									<ul class="popupGallery cf">
										<li>
											<a href="javascript:void(0);" title="（1）喫茶店サービスルート">
												<img src="images/workflow_process01.jpg" width="316" height="218"
													alt="（1）喫茶店サービスルート" />
											</a>
											<p>（1）喫茶店サービスルート</p>
										</li>
										<li>
											<a href="javascript:void(0);" title="（2）入店時対応サービス">
												<img src="images/workflow_process02.jpg" width="316" height="218"
													alt="（2）入店時対応サービス" />
											</a>
											<p>（2）入店時対応サービス</p>
										</li>
										<li>
											<a href="javascript:void(0);" title="（3）お客様に挨拶プロセス">
												<img src="images/workflow_process03.jpg" width="316" height="218"
													alt="（3）お客様に挨拶プロセス" />
											</a>
											<p>（3）お客様に挨拶プロセス</p>
										</li>
										<li>
											<a href="javascript:void(0);" title="（4）来客検知プロセス">
												<img src="images/workflow_process04.jpg" width="316" height="218"
													alt="（4）来客検知プロセス" />
											</a>
											<p>（4）来客検知プロセス</p>
										</li>
									</ul>
								</div>
								<div class="rightCol">
									<p>PRINTEPSにおけるワークフローエディタは、サービス、プロセス、モジュールを組み合わせたワークフローを構築するだけで、知識推論・学習、音声対話、人と物体の画像センシング、マニュピュレーション・動作という4種類の要素知能を統合した総合知能アプリを、エンドユーザが容易に開発できることを目指したWebアプリケーションです。
									</p>
									<p>構築したワークフローは、代表的なロボット開発環境であるROS (Robot Operating
										System)上で実行可能なPythonのソースコードに自動変換することが可能です。</p>
									<p>知能ロボットのために、聞いて話して（音声対話）、考えて（知識推論、機械学習）、見て動いて（画像センシング、マニュピュレーション）という一連の知的振舞いを、エンドユーザが俊敏（アジャイル）に開発して外在化させることを支援します。
									</p>
								</div>
							</div>
							<ul class="imageList cf">
								<li>
									<img src="images/workflow_pdca01.png" width="357" height="196" alt="" />
								</li>
								<li>
									<img src="images/workflow_pdca02.png" width="357" height="196" alt="" />
								</li>
								<li>
									<img src="images/workflow_pdca03.png" width="357" height="196" alt="" />
								</li>
							</ul>
							<p>ユーザが知能ロボットの知的振舞いを見て考察・再発見することにより、知能のPDCAサイクルがまわりはじめ、知能共進化(Co-evolution of
								Intelligence)（人の知能と機械知能が互いに進化し続けていくことで、所与の問題が解決される）を実現できると考えています。</p>
						</div>
						<div class="wrap">
							<h2>このプロジェクトで使用されているロボット</h2>
							<table class="robot_table">
								<tr>
									<td>
										<img src="images/robots/Pepper.png" width="auto" height="130" alt="" />
									</td>
									<td>
										<img src="images/robots/Nao.png" width="auto" height="130" alt="" />
									</td>
									<td>
										<img src="images/robots/Sota.png" width="auto" height="130" alt="" />
									</td>
									<td>
										<img src="images/robots/SociBot.png" width="auto" height="130" alt="" />
									</td>
									<td>
										<img src="images/robots/Hironx.png" width="auto" height="130" alt="" />
									</td>
									<td>
										<img src="images/robots/HSR.png" width="auto" height="130" alt="" />
									</td>
									<td>
										<img src="images/robots/JACO2.png" width="auto" height="130" alt="" />
									</td>
								</tr>
								<tr valign="top" style="text-align: center">
									<td>
										<a href="https://www.aldebaran.com/ja/peppertoha">Pepper<br>&copy;SoftBank</a>
									</td>
									<td>
										<a
											href="https://www.aldebaran.com/ja/xiao-xing-robotutonaotoha">NAO<br>&copy;SoftBank</a>
									</td>
									<td>
										<a href="https://www.vstone.co.jp/products/sota/">Sota<br>&copy;Vstone</a>
									</td>
									<td>
										<a href="https://www.engineeredarts.co.uk/socibot/">SociBot<br>&copy;Engineered
											Arts</p>
										</a>
									</td>
									<td>
										<a href="http://nextage.kawada.jp/hiro/">Hironx<br>&copy;KAWADA</p>
										</a>
									</td>
									<td>
										<a
											href="http://www.toyota.co.jp/jpn/tech/partner_robot/">HSR<br>&copy;TOYOTA</a>
									</td>
									<td>
										<a
											href="http://www.kinovarobotics.com/assistive-robotics/products/manipulation/">JACO2<br>&copy;Kiova</a>
									</td>
								</tr>
							</table>
						</div>
						<!--
															<div class="btnArea">
																<a class="btn" href="http://ja-demo.printeps.org/description" target="_blank">デモサイトに移動する</a>
															</div>
														-->
					</div>

				</div>
				<div class="tab-panel wrap">
					<p>
						PRINTEPSの有用性を評価するために、本プロジェクトでは、ロボット喫茶店を実践しています。以下では、慶應義塾大学矢上祭におけるロボット喫茶店の実践について紹介します。ロボット喫茶店の実践の詳細については、関連文献[1,2]を参照してください。
					</p>
					<h2>ロボット喫茶店の構成</h2>
					<p>
						2017年10月7日（土）と8日（日）に、慶應義塾大学第18回矢上祭において、ロボット喫茶店の実践を行いました．図１に、ロボット喫茶店の構成を示します。入口、カウンター、四人掛けのテーブル2セット、二人掛けのテーブル2セット、ペットボトルディスペンサ、カップディスペンサ、ペットボトル棚、カート、アーム型ロボットJaco2、接客用ロボットPepper、配膳用ロボットHSRを図1のように配置しました。
					</p>
					<ul class="imageList cf">
						<li>
							<a href="images/robot_cafe_fig1.png" target="_blank"><img src="images/robot_cafe_fig1.png"
									width="700" alt="図１：ロボット喫茶店の構成" /></a>図１：ロボット喫茶店の構成
						</li>
					</ul>
					<p>
						入口前方には1台、Kinect
						v2を配置し、主にお客の入店人数の把握や入店検知に用いました。カウンターにはマイクを設置し、注文時の音声認識に用いました。カウンターには、3台のペットボトルディスペンサとカップディスペンサも配置し、オレンジジュース、アップルジュース、アイスティー、ミックスジュースを用意できるようにしました。図２は、カウンター周辺の様子を撮影した写真です。ペットボトル棚には、ドクターペッパー、カルピス、お茶のペットボトルをSサイズとMサイズに分けて図１に示すように配置しました。図３は、ペットボトル棚周辺の様子を撮影した写真です。各テーブルには、全方位カメラを設置し、座席に座っている人を検知することにより、空席状況を把握できるようにしています。また、各テーブルには押しボタンを用意し、ボタンが押された際に、HSRがテーブルまで移動し、顧客が手渡しで空のペットボトルまたは紙コップをHSRに渡すことにより、ペットボトルまたは紙コップを片づけられるようにしました。図３の写真には、HSRがペットボトル棚の横に設置したゴミ箱に、紙コップを捨てている様子が写っています。また、図４は、テーブル周辺の様子を撮影した写真です。
					</p>
					<ul class="imageList cf">
						<li>
							<a href="images/robot_cafe_fig2.png" target="_blank"><img src="images/robot_cafe_fig2.png"
									width="350" alt="図２：カウンター周辺の様子" /></a><br>図２：カウンター周辺の様子
						</li>
						<li>
							<a href="images/robot_cafe_fig3.png" target="_blank"><img src="images/robot_cafe_fig3.png"
									width="350" alt="図３：ペットボトル棚周辺の様子" /></a><br>図３：ペットボトル棚周辺の様子
						</li>
						<li>
							<a href="images/robot_cafe_fig4.png" target="_blank"><img src="images/robot_cafe_fig4.png"
									width="350" alt="図４：テーブル周辺の様子" /></a><br>図４：テーブル周辺の様子
						</li>
					</ul>
					<p>
						Pepperは、注文時の対話や座席案内に用いています。Pepperには、測域センサを搭載し、走行時に自己位置を推定できるようにしました。HSRは、注文内容に応じて、ペットボトル棚からペットボトルを掴み、複数の注文があった場合には、カートを利用し、そうでない場合には、直接、テーブルにペットボトルを運搬しました。Jaco2は、注文内容に応じて、カップディスペンサから紙コップを取り出し、対応するペットボトルディスペンサに紙コップをセットし、注文されたサイズに応じた時間レバーを引いて、顧客に飲み物を提供しました。ミックスジュースが注文された場合には、オレンジジュースとアップルジュースを半分ずつ注ぎます。
					</p>
					<p>
						Kinect
						v2、全方位カメラ、各種ロボットには、制御用のノートPCが有線（図１の実線）または無線（図１の点線）で接続されています。各テーブルに設置した押しボタンはラズベリーパイに接続されています。さらに、PRINTEPSワークフローエディタで作成したワークフローの実行と知識推論のために知識処理用ノートPCを1台、音声対話システム用にノートPCを1台、利用しました。
					</p>
					<h2>ロボット喫茶店のサービス概要と各要素知能の役割</h2>
					<p>
						ロボット喫茶店は、入店時挨拶、座席案内、注文、飲み物の用意と運搬のサービス群から構成されています。以下では、各要素知能がどのようにサービスを実現するために用いられているかについて説明します。
					</p>


					<h3>知識ベース推論</h3>
					<p>
						要素知能「知識ベース推論」では、ワークフロー、ビジネスルール、オントロジーを用いて、ロボット喫茶店における状態の管理やロボットの振舞いを制御します。入店時挨拶と座席案内においては、画像センシングにより得られた客の人数や各客の属性情報からグループ推定を実行し、Kinectのセンシング結果とストリーム推論を用いて入店・退店・退席・空席を検知しています。さらに、ビジネスルールを用いて、喫茶店オーナーの要望を反映したグループごとの接客を行うことを可能としています。注文時においては、ロボット喫茶店におけるメニュー情報（材料、カロリー、金額など）をオントロジーとそのインスタンスとして定義し、音声対話モジュールにその情報を提供し、注文されたメニューから必要な食器や調理手順を生成し、動作計画モジュールを呼び出すなどの処理を行っています。ロボット喫茶店における知識ベース推論の詳細については、関連文献[2]を参照してください。
					</p>

					<h3>音声対話</h3>
					<p>
						要素知能「音声対話」では、主にPepperとマイクを用いて注文対応を行います。メニューとして，SとMサイズのオレンジジュース、アップルジュース、アイスティー、ミックスジュースを用意しており、客が様々な表現方法により、これらのメニューを注文した際に、適切に、メニュー名、サイズ、個数を取得し、ROSのメッセージ型に変換し、多粒度ブラックボードに保存することを実現しています。また、知識ベース推論モジュールと連携し、客のグループや属性に応じたメニューの推薦なども可能としています。音声対話の詳細については、関連文献[3]を参照してください。
					</p>

					<h3>画像センシング</h3>
					<p>
						要素知能「画像センシング」では、主に入口とテーブルのセンシングをKinect v2と全方位カメラを用いて行っています。OKAO Vision
						を用いて人の年齢、性別、表情を推定し、入店客とKinect
						v2までの距離データを取得し、知識ベース推論モジュールと連携して入店検知を実行し、テーブル上の物品や飲食行動を認識しています。入口のセンシングについては関連文献[4]を、テーブルのセンシングについて関連文献[5]を、飲食行動の認識については関連文献[6]を参照してください。
					</p>

					<h3>動作計画</h3>
					<p>
						要素知能「動作計画」では、環境地図を用いたPepperやHSRのロボット喫茶店環境内での移動、Jaco2を用いた飲料準備、HSRを用いた飲料の配膳と片付けなどを実行しています。入口、２人掛けテーブル、４人掛けテーブル、カウンター、待機場所など、環境地図上の場所概念をオントロジーとそのインスタンスとして定義し、PRINTEPSワークフローエディタ上で、指定の場所に移動できます。また、Jaco2は、カップディスペンサーからカップを取得し、注文されたメニューに応じて、ペットボトルディスペンサーの前にカップを置き、ディスペンサーのレバーをサイズに応じた時間分引いて、お客に飲み物を提供することができます。ロボットの移動には関連文献[7]の研究成果を、ロボットの走行時における自己位置推定には
						<a href="http://wiki.ros.org/amcl" target="_blank">amcl</a> を、環境地図の作成には <a
							href="http://wiki.ros.org/gmapping" target="_blank">gmapping</a> を、それぞれ用いています。
					</p>
					<p>
						以上の各要素知能について、ROSのサービス、パブリッシャ、サブスクライバ、メッセージのモジュールがそれぞれ実装され、PRINTEPSワークフローエディタ上でワークフローを構築し、ワークフローから自動生成されたプログラムをROS環境上で実行することができるようになっています。
					</p>

					<h2>ロボット喫茶店のワークフロー</h2>
					<p>
						上記で説明したロボット喫茶店のアプリケーションを、PRINTEPSワークフローエディタを用いて実装しました。図５は、ロボット喫茶店のサービス層を示しています。サービス層には，主に，「入店時対応」、「座席案内」、「カウンター飲物用意」、「テーブル飲物用意」サービスが作成されています。「常駐」サービスは、センシングの結果により実行されるプロセス群をまとめており、「注文対応」プロセスなどは、「常駐」サービス内で定義されています。図６は、「入店時対応」サービスの展開図を示しています。図７は、「入店時対応」サービス内で実行される「お客様に挨拶」プロセスを展開した図です。
					</p>

					<ul class="imageList cf">
						<li>
							<a href="images/robot_cafe_fig5.png" target="_blank"><img src="images/robot_cafe_fig5.png"
									width="380" alt="図５：ロボット喫茶店のサービス層" /></a><br>図５：ロボット喫茶店のサービス層
						</li>
						<li>
							<a href="images/robot_cafe_fig6.png" target="_blank"><img src="images/robot_cafe_fig6.png"
									width="380" alt="図６：「入店時対応サービス」の展開図" /></a><br>図６：「入店時対応」サービスの展開図
						</li>
					</ul>
					<ul class="imageList cf">
						<li>
							<a href="images/robot_cafe_fig7.png" target="_blank"><img src="images/robot_cafe_fig7.png"
									width="600" alt="図７：「お客様に挨拶」プロセスの展開図" /></a><br>図７：「お客様に挨拶」プロセスの展開図
						</li>
					</ul>
					<h2>関連文献</h2>
					<ol class="related-work">
						<li>Takeshi Morita, Naho Kashiwagi, Ayanori Yorozu, Hideo Suzuki, Takahira Yamaguchi,
							“Evaluation of a Multi-Robot Cafe based on Service Quality Dimensions”, The Review of
							Socionetwork Strategies, Springer, pp.1-22, 2019.</li>
						<li>Takeshi Morita, Kodai Nakamura, Hiroki Komatsushiro, Takahira Yamaguchi, “PRINTEPS: An
							Integrated Intelligent Application Development Platform based on Stream Reasoning and ROS”,
							The Review of Socionetwork Strategies, Springer, Vol. 12, Issue 1, pp 71–96, 2018.</li>
						<li>西村良太, 眞鍋麟太郎, 中野有紀子，"ROSアーキテクチャに基づき情報統合・共有を行う音声対話システムの開発", 第79回人工知能学会言語・音声理解と対話処理研究会
							(SIG-SLUD), Vol. B506, No. 15,
							pp. 79–84, 2017.</li>
						<li>田中康浩, 中山祐介, 齋藤俊太, 斎藤英雄, "実践知能アプリケーション開発プラットフォームPRINTEPSのためのRGB-Dカメラによる来場者検出と属性判定",
							情報処理学会第78回全国大会講演論文集, pp. 233–234, 2016.
						</li>
						<li>番原常公, 中山祐介, 齋藤俊太, 斎藤英雄, "実践知能アプリケーション開発プラットフォームPRINTEPSのためのRGB-Dカメラによるテーブルトップ作業空間の状況認識",
							情報処理学会第78回全国大会講演論文集, pp. 231–232,
							2016.</li>
						<li>番原常公, 八馬遼, 家永直人, 小篠裕子, 斎藤英雄, "画像による物体検出を用いた飲食行動認識の検討", 信学 技報, Vol. 116, No. 461, pp. 95–98,
							2017.</li>
						<li>Yorozu, A. and Takahashi, M., "Obstacle avoidance with translational and efficient
							rotational motion control
							considering movable gaps and footprint for autonomous mobile robot", International Journal
							of Control, Automation
							and Systems, Vol. 14, No. 5, pp. 1352–1364, 2016.</li>
					</ol>
				</div>
				<div class="tab-panel wrap">
					<p>
						PRINTEPSの有用性を評価するために、本プロジェクトでは、小学校の教諭と連携して、PRINTEPSを用いた教諭ロボット連携授業の開発と実証実験を行っています。ここでは、慶應義塾幼稚舎と東京都杉並区立浜田山小学校での実証実験を紹介します。
					</p>

					<h2>シナリオエディタによる教諭と複数ロボット連携授業の開発</h2>
					<p>
						PRINTEPSワークフローエディタを用いて、教諭が授業の流れを日本語ワークフローにより記述し、ワークフローをプログラムコードに自動変換することが可能です。しかしながら、授業の流れは、教諭・生徒・ロボット・表示装置等の情報機器、人と人、人と機械（ロボット・情報機器）、機械と機械（以下、人と機械をまとめてアクターと呼ぶ）間の情報インタラクションであり、処理の流れではなくインタラクションを記述して、授業全体を俯瞰したいという要望が教諭から出されました。そこで、アクター間で交換される知識情報を記述するシナリオエディタを開発しました。
					</p>
					<p>
						慶應義塾幼稚舎６年生４クラス（１クラス３６名）を対象にして、理科「人の体の仕組み」を学習単元とし、人型ロボットPepper（ペッパー）と
						表情が変化するSociBot（ソシボット）を利用した授業において、シナリオエディタを利用しました。
						本授業では、数名の児童から構成される各班で、二択か三択の中から解答の札を選んで、札を立てると、机上の画像センサーがその札を認識し、パソコンが各グループの成績を自動的に付けていくアプリケーションをシナリオエディタを用いて開発しました。
					</p>
					<p>
						図１は、シナリオエディタで開発した授業開始に関するシナリオです。このシナリオでは、教諭とPepperがインタラクションを取りながら、「カエルの解剖」の振り返りクイズに関する導入説明を行っています。Pepperレーンで、「頭が触れられるまで待機」ノードが複数回現れていますが、教諭が児童に話しかける間（この話しかけは教諭のアドリブとし、シナリオには明記されていません）、Pepperに待機させ、教諭がPepperの頭に触れるとその動作が「頭が触れられるまで待機」ノードの出力となり、次のノードに移動して、Pepperが記述されているテキストを読み上げます。また、ディスプレイレーンでは、教室のディスプレイにクイズや画像などを提示することができます。
					</p>
					<p>
						SociBotは、英国製のロボットで、顔の中にLED電球が埋め込まれ、顔色や表情を変えられる人型ロボットです。SociBotは、据え置き型で移動できない上半身だけのロボットだったため、移動可能型に拡張し、図２の写真のように、表情を変化させながら、教室を周回できるようにしました。
					</p>
					<p>
						シナリオエディタと慶應義塾幼稚舎における教諭ロボット連携授業の詳細については、関連文献[2,4,5,6,7]を参照してください。
					</p>

					<ul class="imageList cf">
						<li>
							<a href="images/ta_robot_fig1.png" target="_blank"><img src="images/ta_robot_fig1.png"
									width="350" alt="図１：シナリオエディタで開発した授業開始に関するシナリオ" /></a>図１：シナリオエディタで開発した授業開始に関するシナリオ
						</li>
						<li>
							<a href="images/ta_robot_fig2.jpg" target="_blank"><img src="images/ta_robot_fig2.jpg"
									width="350" alt="図２：表情を変えて教室を周回するSociBot" /></a>図２：表情を変えて教室を周回するSociBot
						</li>
					</ul>

					<h2>授業シナリオ検索エンジンの開発</h2>
					<p>
						PRINTEPSシナリオエディタを用いれば、教諭一人でも授業支援ロボットのアプリケーションを開発できる状況に近づいてきましたが、開発に時間がかかることが課題でした。特に、教諭ロボット連携授業を初めて経験する教諭にとっては、PRINTEPSシナリオエディタ利用のハードルは高いです。そこで今までに、社会（地球温暖化、自然の未来）、理科（てこの規則性、人の体の仕組み、振り子の運動）、探求（総合科目）（エネルギーの仕組み）に関する教諭ロボット連携授業を開発してきたので、これらの授業シナリオ群を構造化し、いくつかの観点から授業シナリオを検索できるエンジンを開発することにしました。
					</p>
					<p>
						本検索エンジンでは、学習単元・授業進行・ロボット操作という３種類の索引群から検索できるようにし（図３、図４、図５）、３種類の索引群を使って検索条件と照合した過去の授業シナリオに、説明文と動画を付けて提示し、ユーザはそれを元に自分の授業シナリオを開発できます（図６）。
					</p>
					<p>
						振り子の実験を対象にし、東京都杉並区立浜田山小学校の教諭ロボット連携授業未経験の教諭２名に本検索エンジンを利用し評価してもらいました。本実験では、音楽に合わせて、振り子の長さ・おもりの重さ・振れ幅といった条件を変えながら振り子を振らせて周期を測定する実験を繰りことにより「ふりこの一往復にかかる時間は何によって決まるのだろうか」を考えていきます。本実験では、人型ロボットＮＡＯ（ナオ）、ロボットアーム、センサーが連携して、振り子を振らせ、周期を自動測定し、その測定精度の高さを示しました。
					</p>
					<p>
						実験実施後、２名の教諭にインタビューしたところ「ロボットを初めて触る人が陥りがちな典型的な失敗事例を事前に知ることができ、授業設計に役立てることができた」「カテゴリの絞り込み・組み合わせによって探したい授業場面を見つけられるのは便利であると思った」という評価が得られる一方、「本システムに頼りすぎると創造性が阻害されたり、硬直化した授業づくりになったりしないか？」というコメントも提示されました。
					</p>
					<p>
						授業シナリオ検索エンジンと浜田山小学校における教諭ロボット連携授業の詳細については、関連文献[1,3]を参照してください。
					</p>

					<ul class="imageList cf">
						<li>
							<a href="images/ta_robot_fig3.png" target="_blank"><img src="images/ta_robot_fig3.png"
									width="350" alt="図３：学習単元に関する索引群" /></a>図３：学習単元に関する索引群
						</li>
						<li>
							<a href="images/ta_robot_fig4.png" target="_blank"><img src="images/ta_robot_fig4.png"
									width="350" alt="図４：授業進行に関する索引群" /></a>図４：授業進行に関する索引群
						</li>
						<li>
							<a href="images/ta_robot_fig5.png" target="_blank"><img src="images/ta_robot_fig5.png"
									width="350" alt="図５：ロボット操作法に関する索引群" /></a>図５：ロボット操作法に関する索引群
						</li>
					</ul>

					<ul class="imageList cf">
						<li>
							<a href="images/ta_robot_fig6.png" target="_blank"><img src="images/ta_robot_fig6.png"
									width="500" alt="図６：授業シナリオ検索エンジンのスクリーンショット" /></a>図６：授業シナリオ検索エンジンのスクリーンショット
						</li>
					</ul>

					<h2>関連文献</h2>
					<ol class="related-work">
						<li>森田武史，高橋尚也、小須田瑞季、山口高平, "知識チャンク再利用支援ツールを利用した教師ロボット連携授業システムの開発と評価"，情報システム学会論文誌, Vol. 15, No.
							1, pp.18-37, 2019.</li>
						<li>Takeshi Morita, Shunsuke Akashiba, Chihiro Nishimoto, Naoya Takahashi, Reiji Kukihara, Misae
							Kuwayama, Takahira Yamaguchi, “A Practical Teacher-Robot Collaboration Lesson Application
							Based on PRINTEPS”, The Review of Socionetwork Strategies, Springer, Vol. 12, Issue 1, pp
							97–126, 2018.</li>
						<!--						<li>"AIロボSOTAと考えた 私たちの温暖化対策"，読売教育ネットワーク 会報49号，pp. 2-3，2019.（<a
								href="https://kyoiku.yomiuri.co.jp/kaihou49a.pdf" target="_blank">PDF</a>）</li> -->
						<li>"校長先生とロボット助手 理科の実験授業"，読売教育ネットワーク 会報38号，pp. 2-3，2018.（<a
								href="https://kyoiku.yomiuri.co.jp/kaihou38a.pdf" target="_blank">PDF</a>）</li>
						<li>西本智浩，赤柴駿介，高橋尚也，森田武史，柊原礼二，桑山美冴，山口高平，”PRINTEPS による教師ロボット連携授業アプリの開発”，信学技報, Vol. 116, No. 462,
							CNR2016-30, pp. 63-68, 2017.</li>
						<li>石川礼，小篠裕子，斎藤英雄，"PRINTEPSにおける教師ロボット連携授業のためのクイズモジュール"，信学技報，Vol. 116，No. 462，pp.69-74，2017.</li>
						<li>田中康浩，小篠裕子，斎藤英雄，"PRINTEPSにおける教師ロボット連携授業のためのARモジュール "，信学技報"，Vol. 116，No. 462，pp.75-80，2017.
						</li>
						<li>"慶應義塾幼稚舎でロボットが理科の授業"，読売教育ネットワーク 会報24号，p. 6，2016.（<a
								href="https://kyoiku.yomiuri.co.jp/kaihou24.pdf" target="_blank">PDF</a>）</li>

					</ol>
				</div>
			</div>
		</section>

		<section id="member" class="content member">
			<h1>研究メンバー</h1>
			<div class="wrap cf">
				<div class="group">
					<div class="groupBox" style="width: 350px;">
						<h2>知識推論</h2>
						<ul>
							<li>
								<img src="images/profile_gp01_01.jpg" width="97" height="110" alt="山口高平" />
								<strong>
									<a href="http://www.yamaguti.comp.ae.keio.ac.jp/index.ja.html">山口 高平</a>
								</strong>慶應義塾大学理工学部 <div>(研究代表者)</div>
							</li>
							<li>
								<img src="images/profile_gp01_02.jpg" width="97" height="110" alt="森田武史" />
								<strong>
									<a href="http://researchmap.jp/t_morita/">森田 武史</a>
								</strong>慶應義塾大学理工学部
							</li>
							<li>
								<img src="images/profile_gp01_03.jpg" width="97" height="110" alt="阿部秀尚" />
								<strong>
									<a href="http://abe-lab.jp/">阿部 秀尚</a>
								</strong>文教大学情報学部
							</li>
							<li>
								<img src="images/profile_dummy.jpg" width="97" height="110" alt="鈴木忠" />
								<strong>
									<a href="http://www.shirayuri.ac.jp/course/teacher/suzuki_tadashi.html">鈴木 忠</a>
								</strong>白百合女子大学文学部
							</li>
							<li>
								<img src="images/profile_dummy.jpg" width="97" height="110" alt="山﨑準二" />
								<strong>山﨑 準二</strong>学習院大学文学部
							</li>
						</ul>
					</div>
					<div class="groupBox">
						<h2>対話継続</h2>
						<ul>
							<li>
								<img src="images/profile_gp02_01.jpg" width="97" height="110" alt="小林一郎" />
								<strong>
									<a href="http://www.koba.is.ocha.ac.jp/wordpress/?lang=ja">小林 一郎</a>
								</strong>お茶の水女子大学理学部 <div>(主たる共同研究者)</div>
							</li>
						</ul>
					</div>
					<div class="groupBox">
						<h2>音声対話</h2>
						<ul>
							<li>
								<img src="images/profile_gp03_01.jpg" width="97" height="110" alt="中野有紀子" />
								<strong>
									<a href="http://iui.ci.seikei.ac.jp/">中野 有紀子</a>
								</strong>成蹊大学理工学部 <div>(主たる共同研究者)</div>
							</li>
							<li>
								<img src="images/profile_gp03_02.jpg" width="97" height="110" alt="高瀬裕" />
								<strong>
									<a href="http://iui.ci.seikei.ac.jp/~takase/">高瀬 裕</a>
								</strong>成蹊大学理工学部
							</li>
						</ul>
					</div>
					<div class="groupBox">
						<h2>画像センシング</h2>
						<ul>
							<li>
								<img src="images/profile_gp04_01.jpg" width="97" height="110" alt="斎藤英雄" />
								<strong>
									<a href="http://www.hvrl.ics.keio.ac.jp/">斎藤 英雄</a>
								</strong>慶應義塾大学理工学部 <div>(主たる共同研究者)</div>
							</li>
							<li>
								<img src="images/profile_gp04_02.jpg" width="97" height="110" alt="杉本麻樹" />
								<strong>
									<a href="http://im-lab.net/">杉本 麻樹</a>
								</strong>慶應義塾大学理工学部
							</li>
							<li>
								<img src="images/profile_gp04_03.jpg" width="97" height="110" alt="小篠裕子" />
								<strong>小篠 裕子</strong>慶應義塾大学大学院 <div>理工学研究科</div>
							</li>
						</ul>
					</div>

					<div class="groupBox">
						<h2>動作</h2>
						<ul>
							<li>
								<img src="images/profile_gp05_01.jpg" width="97" height="110" alt="高橋正樹" />
								<strong>
									<a href="http://www.yt.sd.keio.ac.jp/">高橋 正樹</a>
								</strong>慶應義塾大学理工学部 <div>(主たる共同研究者)</div>
							</li>
							<li>
								<img src="images/profile_gp05_02.jpg" width="97" height="110" alt="萬礼応" />
								<strong>萬 礼応</strong>慶應義塾大学大学院 <div>理工学研究科</div>
							</li>
						</ul>
					</div>
				</div>
			</div>
		</section>

		<div class="jst_logo">
			<a href="http://www.jst.go.jp/">
				<img src="images/jstlogo2015_rgb_ja.svg" height="80px" />
			</a>
		</div>
	</article>

	<footer class="globalFooter">
		<br>
		Copyright (C) 2014 - 2018 YAMAGUCHI CREST project All Rights Reserved.
	</footer>
	<!-- /.footerGroup -->


	<!-- Loading JavaScript -->
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
	<script type="text/javascript" src="js/jquery.easing.1.3.js"></script>
	<script type="text/javascript" src="js/jquery.transit.min.js"></script>
	<script type="text/javascript" src="js/jQueryAutoHeight.js"></script>
	<script type="text/javascript" src="js/common.js"></script>


</body>

</html>